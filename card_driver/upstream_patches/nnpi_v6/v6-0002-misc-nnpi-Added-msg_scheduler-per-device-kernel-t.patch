From 5a9219a276d5c9e46945df68895270a550f4e31d Mon Sep 17 00:00:00 2001
From: Guy Zadicario <guy.zadicario@intel.com>
Date: Sun, 29 Mar 2020 22:41:42 +0300
Subject: [PATCH v6 02/19] misc: nnpi: Added msg_scheduler per-device kernel
 thread

This adds the msg_scheduler object which is allocated for each
NNP-I device. It includes a kernel thread which manages multiple
"command queues", each command queue is a list of commands that
needs to be sent to the NNP-I device through the h/w command queue.

The thread in msg_scheduler schedules sending of the commands and
it is a single point where the write_mesg function of the "pci" layer
is called (the function which puts the message on the h/w command queue).

A "command" to the device is formed as N number of unsigned 64-bit values, where N is
either 1, 2 or 3.

The msg_scheduler object is created on device creation and destoyed on device removal.
The "public_cmdq" queue object is also allocated which will be used to send driver
generated commands to the NNP-I device.

Signed-off-by: Guy Zadicario <guy.zadicario@intel.com>
Reviewed-by: Vaibhav Agarwal <vaibhav.agarwal@intel.com>
---
 drivers/misc/intel-nnpi/Makefile        |   2 +-
 drivers/misc/intel-nnpi/device.c        |  71 +++-
 drivers/misc/intel-nnpi/device.h        |  23 +-
 drivers/misc/intel-nnpi/msg_scheduler.c | 557 ++++++++++++++++++++++++++++++++
 drivers/misc/intel-nnpi/msg_scheduler.h | 147 +++++++++
 5 files changed, 796 insertions(+), 4 deletions(-)
 create mode 100644 drivers/misc/intel-nnpi/msg_scheduler.c
 create mode 100644 drivers/misc/intel-nnpi/msg_scheduler.h

diff --git a/drivers/misc/intel-nnpi/Makefile b/drivers/misc/intel-nnpi/Makefile
index efe96fa..ae2ce56 100644
--- a/drivers/misc/intel-nnpi/Makefile
+++ b/drivers/misc/intel-nnpi/Makefile
@@ -6,6 +6,6 @@
 
 obj-m	:= intel_nnpidrv.o
 
-intel_nnpidrv-y := nnpdrv_main.o pcie.o device.o
+intel_nnpidrv-y := nnpdrv_main.o pcie.o device.o msg_scheduler.o
 
 ccflags-y += -I$(srctree)/$(src)/if_include
diff --git a/drivers/misc/intel-nnpi/device.c b/drivers/misc/intel-nnpi/device.c
index cdd35e9..fb7adae 100644
--- a/drivers/misc/intel-nnpi/device.c
+++ b/drivers/misc/intel-nnpi/device.c
@@ -14,21 +14,31 @@
 #include <linux/wait.h>
 #include <linux/sched/clock.h>
 #include <linux/mutex.h>
+#include <linux/debugfs.h>
 #include "nnp_log.h"
 #include "nnp_debug.h"
 #include "pcie.h"
 
 static struct ida s_dev_ida;
+struct dentry *s_debugfs_dir;
 
 int nnpdrv_device_init(void)
 {
+	s_debugfs_dir = debugfs_create_dir("intel_nnpi", NULL);
+	if (IS_ERR_OR_NULL(s_debugfs_dir)) {
+		nnp_log_info(START_UP_LOG, "failed to initialize debugfs dir\n");
+		s_debugfs_dir = NULL;
+	}
+
 	ida_init(&s_dev_ida);
+
 	return 0;
 }
 
 void nnpdrv_device_fini(void)
 {
 	ida_destroy(&s_dev_ida);
+	debugfs_remove_recursive(s_debugfs_dir);
 }
 
 /*
@@ -45,6 +55,31 @@ int nnpdrv_device_process_messages(struct nnp_device *nnpdev,
 	return hw_nof_msg;
 }
 
+static int cmdq_sched_handler(u64 *msg, int size, void *hw_data)
+{
+	struct nnp_device *nnpdev = (struct nnp_device *)hw_data;
+	int ret;
+
+	ret = nnpdev->hw_ops->write_mesg(nnpdev->hw_handle, msg, size, NULL);
+
+	return ret;
+}
+
+struct msg_scheduler_queue *nnpdrv_create_cmd_queue(struct nnp_device *nnpdev,
+						    u32                weight)
+{
+	return msg_scheduler_queue_create(nnpdev->cmdq_sched,
+					  nnpdev,
+					  cmdq_sched_handler,
+					  weight);
+}
+
+int nnpdrv_destroy_cmd_queue(struct nnp_device          *nnpdev,
+			     struct msg_scheduler_queue *q)
+{
+	return msg_scheduler_queue_destroy(nnpdev->cmdq_sched, q);
+}
+
 int nnpdrv_device_create(void                              *hw_handle,
 			 const struct nnp_hw_device_info   *hw_device_info,
 			 const struct nnpdrv_device_hw_ops *hw_ops,
@@ -80,6 +115,30 @@ int nnpdrv_device_create(void                              *hw_handle,
 	nnpdev->hw_device_info = hw_device_info;
 	nnpdev->hw_ops = hw_ops;
 
+	if (s_debugfs_dir) {
+		nnpdev->debugfs_dir = debugfs_create_dir(&nnpdev->name[6],
+							 s_debugfs_dir);
+		if (IS_ERR_OR_NULL(nnpdev->debugfs_dir))
+			nnpdev->debugfs_dir = NULL;
+	}
+
+	nnpdev->cmdq_sched = msg_scheduler_create();
+	if (!nnpdev->cmdq_sched) {
+		nnp_log_err(START_UP_LOG, "failed to create msgQ scheduler\n");
+		goto err_exit;
+	}
+
+	if (nnpdev->debugfs_dir)
+		msg_scheduler_init_debugfs(nnpdev->cmdq_sched,
+					   nnpdev->debugfs_dir,
+					   "msg_sched");
+
+	nnpdev->public_cmdq = nnpdrv_create_cmd_queue(nnpdev, 1);
+	if (!nnpdev->public_cmdq) {
+		nnp_log_err(START_UP_LOG, "failed to create public command q\n");
+		goto err_exit;
+	}
+
 	kref_init(&nnpdev->ref);
 	*out_nnpdev = nnpdev;
 
@@ -88,8 +147,12 @@ int nnpdrv_device_create(void                              *hw_handle,
 	return 0;
 
 err_exit:
+	nnpdrv_destroy_cmd_queue(nnpdev, nnpdev->public_cmdq);
+	if (nnpdev->cmdq_sched)
+		msg_scheduler_destroy(nnpdev->cmdq_sched);
 	if (-1 != nnpdev->id)
 		ida_simple_remove(&s_dev_ida, nnpdev->id);
+	debugfs_remove_recursive(nnpdev->debugfs_dir);
 	kfree(nnpdev);
 	nnp_log_err(START_UP_LOG, "create device failed\n");
 	return ret;
@@ -136,8 +199,14 @@ static void nnpdrv_free_device(struct work_struct *work)
 
 	NNP_ASSERT(nnpdev->release_completion);
 
-	ida_simple_remove(&s_dev_ida, nnpdev->id);
+	if (nnpdrv_destroy_cmd_queue(nnpdev, nnpdev->public_cmdq))
+		nnp_log_err(GO_DOWN_LOG, "cmd queue destruction went wrong\n");
+
+	if (msg_scheduler_destroy(nnpdev->cmdq_sched))
+		nnp_log_err(GO_DOWN_LOG, "cmd queue scheduler destruction went wrong\n");
 
+	ida_simple_remove(&s_dev_ida, nnpdev->id);
+	debugfs_remove_recursive(nnpdev->debugfs_dir);
 	kfree(nnpdev);
 	complete(completion);
 }
diff --git a/drivers/misc/intel-nnpi/device.h b/drivers/misc/intel-nnpi/device.h
index 942da77..73a2681 100644
--- a/drivers/misc/intel-nnpi/device.h
+++ b/drivers/misc/intel-nnpi/device.h
@@ -8,10 +8,12 @@
 
 #include <linux/kernel.h>
 #include <linux/workqueue.h>
+#include <linux/debugfs.h>
 #include <linux/kref.h>
 #include <linux/completion.h>
 #include <linux/idr.h>
 #include "pcie.h"
+#include "msg_scheduler.h"
 
 #define NNP_MAX_DEVS		32
 #define DEVICE_NAME_LEN         32
@@ -24,8 +26,13 @@ struct nnp_device {
 	struct completion *release_completion;
 	struct work_struct free_work;
 
-	u32             id;
+	struct msg_scheduler       *cmdq_sched;
+	struct msg_scheduler_queue *public_cmdq;
+
+	u32            id;
 	char           name[DEVICE_NAME_LEN];
+
+	struct dentry *debugfs_dir;
 };
 
 int nnpdrv_device_init(void);
@@ -36,6 +43,19 @@ int nnpdrv_device_create(void                              *hw_handle,
 			 const struct nnpdrv_device_hw_ops *hw_ops,
 			 struct nnp_device                **out_nnpdev);
 
+struct msg_scheduler_queue *nnpdrv_create_cmd_queue(struct nnp_device *nnpdev,
+						    u32                weight);
+
+int nnpdrv_destroy_cmd_queue(struct nnp_device          *nnpdev,
+			     struct msg_scheduler_queue *q);
+
+static inline int nnpdrv_msg_scheduler_queue_add_msg(
+					struct msg_scheduler_queue *queue,
+					u64 *msg, int size)
+{
+	return msg_scheduler_queue_add_msg(queue, msg, size);
+}
+
 void nnpdrv_device_get(struct nnp_device *nnpdev);
 int nnpdrv_device_put(struct nnp_device *nnpdev);
 
@@ -47,5 +67,4 @@ void nnpdrv_card_doorbell_value_changed(struct nnp_device *nnpdev,
 int nnpdrv_device_process_messages(struct nnp_device *nnpdev,
 				   u64               *msg,
 				   u32                size);
-
 #endif
diff --git a/drivers/misc/intel-nnpi/msg_scheduler.c b/drivers/misc/intel-nnpi/msg_scheduler.c
new file mode 100644
index 0000000..26ce662
--- /dev/null
+++ b/drivers/misc/intel-nnpi/msg_scheduler.c
@@ -0,0 +1,557 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+
+/********************************************
+ * Copyright (C) 2019-2020 Intel Corporation
+ ********************************************/
+
+/*
+ * [Desciption]: message scheduler implementation.
+ * create scheduler to handle message sending of some device.
+ * This program allow device to create scheduler and manage several
+ * queues of messages which will be handled in RR scheduling scheme.
+ */
+
+#include "msg_scheduler.h"
+#include <linux/slab.h>
+#include <linux/err.h>
+#include <linux/interrupt.h>
+#include <linux/sched.h>
+#include <linux/wait.h>
+#include <linux/spinlock.h>
+#include "nnp_debug.h"
+#include "nnp_log.h"
+#include <linux/list.h>
+#include <linux/mutex.h>
+#include <linux/jiffies.h>
+#include <linux/kthread.h>
+#include <linux/seq_file.h>
+
+struct msg_entry {
+	u64 msg[MSG_SCHED_MAX_MSG_SIZE];
+	u32 size;
+	struct list_head node;
+};
+
+/*
+ * [Description]: messages scheduler main thread function.
+ * loop over all the queues lists of messages in RR fashion,
+ * [in] data :  shceduler data
+ */
+static int msg_scheduler_thread_func(void *data)
+{
+	struct msg_scheduler *dev_sched = (struct msg_scheduler *)data;
+	struct msg_scheduler_queue *queue_node;
+	struct msg_entry *msg_list_node;
+	int ret;
+	int i;
+	int is_empty;
+	u32 local_total_msgs_num = 0;
+	u32 left = 0;
+
+	nnp_log_debug(GENERAL_LOG, "msg scheduler thread started\n");
+
+	while (!kthread_should_stop()) {
+		mutex_lock(&dev_sched->destroy_lock);
+		spin_lock_bh(&dev_sched->queue_lock_bh);
+		set_current_state(TASK_INTERRUPTIBLE);
+		if (dev_sched->total_msgs_num == local_total_msgs_num &&
+		    left == 0) {
+			mutex_unlock(&dev_sched->destroy_lock);
+			spin_unlock_bh(&dev_sched->queue_lock_bh);
+			/* wait until messages arrive to some queue */
+			schedule();
+			mutex_lock(&dev_sched->destroy_lock);
+			spin_lock_bh(&dev_sched->queue_lock_bh);
+		}
+		set_current_state(TASK_RUNNING);
+
+		local_total_msgs_num = dev_sched->total_msgs_num;
+		left = 0;
+
+		is_empty = list_empty(&dev_sched->queues_list_head);
+		if (!is_empty)
+			queue_node =
+				list_first_entry(&dev_sched->queues_list_head,
+						 struct msg_scheduler_queue,
+						 queues_list_node);
+
+		spin_unlock_bh(&dev_sched->queue_lock_bh);
+
+		if (is_empty) {
+			mutex_unlock(&dev_sched->destroy_lock);
+			continue;
+		}
+
+		ret = 0;
+
+		while (&queue_node->queues_list_node !=
+		       &dev_sched->queues_list_head) {
+			if (queue_node->msgs_num == 0)
+				goto skip_queue;
+
+			for (i = 0; i < queue_node->handle_cont; i++) {
+				spin_lock_bh(&queue_node->list_lock_bh);
+#ifdef DEBUG
+				queue_node->sched_count++;
+#endif
+				is_empty =
+					list_empty(&queue_node->msgs_list_head);
+				if (!is_empty) {
+					msg_list_node = list_first_entry(
+						&queue_node->msgs_list_head,
+						struct msg_entry, node);
+#ifdef DEBUG
+					queue_node->pre_send_count++;
+#endif
+				}
+				spin_unlock_bh(&queue_node->list_lock_bh);
+
+				if (is_empty)
+					break;
+
+				ret = queue_node->msg_handle(msg_list_node->msg,
+						msg_list_node->size,
+						queue_node->device_hw_data);
+				if (ret) {
+#ifdef DEBUG
+					queue_node->send_failed_count++;
+#endif
+					break;
+				}
+
+				spin_lock_bh(&queue_node->list_lock_bh);
+#ifdef DEBUG
+				queue_node->post_send_count++;
+#endif
+				list_del(&msg_list_node->node);
+				queue_node->msgs_num--;
+				spin_unlock_bh(&queue_node->list_lock_bh);
+				kmem_cache_free(dev_sched->slab_cache_ptr,
+						msg_list_node);
+
+				if (!queue_node->msgs_num)
+					wake_up_all(&queue_node->flush_waitq);
+			}
+
+			/*
+			 * if failed to write into command queue, no point
+			 * trying rest of the message queues
+			 */
+			if (ret)
+				break;
+
+			left += queue_node->msgs_num;
+skip_queue:
+			spin_lock_bh(&dev_sched->queue_lock_bh);
+			queue_node = list_next_entry(queue_node,
+						     queues_list_node);
+			spin_unlock_bh(&dev_sched->queue_lock_bh);
+		}
+
+		mutex_unlock(&dev_sched->destroy_lock);
+
+		if (ret) {
+			nnp_log_err(GENERAL_LOG,
+				    "FATAL: failed writing to command queue - invalidating all queues\n");
+			msg_scheduler_invalidate_all(dev_sched);
+		}
+	}
+
+	nnp_log_debug(GENERAL_LOG, "Thread Stopping\n");
+
+	do_exit(0);
+}
+
+/*
+ * [Description]: create new message queue.
+ *
+ * [in] scheduler
+ * [in] msg_handle
+ * [in] conti_msgs
+ */
+struct msg_scheduler_queue *msg_scheduler_queue_create(
+				struct msg_scheduler *scheduler,
+				void                 *device_hw_data,
+				hw_handle_msg         msg_handle,
+				u32                   conti_msgs)
+{
+	struct msg_scheduler_queue *queue;
+
+	if (!msg_handle) {
+		nnp_log_err(START_UP_LOG, "FATAL: NULL pointer as msg handler\n");
+		return NULL;
+	}
+
+	queue = kzalloc(sizeof(*queue), GFP_NOWAIT);
+	if (!queue)
+		return NULL;
+
+	INIT_LIST_HEAD(&queue->msgs_list_head);
+	spin_lock_init(&queue->list_lock_bh);
+	queue->msgs_num = 0;
+
+	if (!conti_msgs)
+		queue->handle_cont = 1;
+	else
+		queue->handle_cont = conti_msgs;
+
+	queue->device_hw_data = device_hw_data;
+	queue->msg_handle = msg_handle;
+	queue->scheduler = scheduler;
+	init_waitqueue_head(&queue->flush_waitq);
+
+	spin_lock_bh(&scheduler->queue_lock_bh);
+	list_add_tail(&queue->queues_list_node, &scheduler->queues_list_head);
+	spin_unlock_bh(&scheduler->queue_lock_bh);
+
+	return queue;
+}
+
+/*
+ * [description]: remove queue from scheduler.
+ * - free all messages of the queue
+ * - free queue node from queues list
+ * [in]: scheduler
+ * [in]: queue :  queue
+ */
+int msg_scheduler_queue_destroy(struct msg_scheduler       *scheduler,
+				struct msg_scheduler_queue *queue)
+{
+	struct msg_entry *msg_list_node;
+
+	if (!queue || queue->scheduler != scheduler) {
+		nnp_log_err(GO_DOWN_LOG, "NULL pointer or wrong scheduler\n");
+		return -EINVAL;
+	}
+
+	mutex_lock(&scheduler->destroy_lock);
+
+	/* destroy all the messages of the queue */
+	spin_lock_bh(&queue->list_lock_bh);
+	while (!list_empty(&queue->msgs_list_head)) {
+		msg_list_node = list_first_entry(&queue->msgs_list_head,
+						 struct msg_entry, node);
+		list_del(&msg_list_node->node);
+		kmem_cache_free(scheduler->slab_cache_ptr, msg_list_node);
+	}
+	spin_unlock_bh(&queue->list_lock_bh);
+
+	/* destroy the queue */
+	spin_lock_bh(&queue->scheduler->queue_lock_bh);
+	list_del(&queue->queues_list_node);
+	spin_unlock_bh(&queue->scheduler->queue_lock_bh);
+	kfree(queue);
+	mutex_unlock(&scheduler->destroy_lock);
+
+	return 0;
+}
+
+/*
+ * [Description]: wait until a message queue is flushed out and empty
+ * [in] queue
+ */
+int msg_scheduler_queue_flush(struct msg_scheduler_queue *queue)
+{
+	int ret;
+
+	/* Wait for the queue to be empty */
+	ret = wait_event_interruptible(queue->flush_waitq,
+				       list_empty(&queue->msgs_list_head));
+
+	return ret;
+}
+
+/*
+ * [Description]: add message to existing queue.
+ * [in] queue
+ * [in] msg
+ * [in] size
+ */
+int msg_scheduler_queue_add_msg(struct msg_scheduler_queue *queue,
+				u64                        *msg,
+				unsigned int               size)
+{
+	unsigned int i;
+	struct msg_entry *msg_list_node;
+	u32 invalid_queue;
+
+	if (!queue || !msg) {
+		nnp_log_err(GENERAL_LOG,
+			    "NULL pointer received as queue list/msg\n");
+		return -EINVAL;
+	}
+
+	if (size > MSG_SCHED_MAX_MSG_SIZE) {
+		nnp_log_err(GENERAL_LOG,
+			    "invalid message size received, size: %u.\n",
+			    size);
+		return -EINVAL;
+	}
+
+	/* if queue flaged as invalid - silently ignore the message */
+	if (queue->invalid)
+		return 0;
+
+	msg_list_node = kmem_cache_alloc(queue->scheduler->slab_cache_ptr,
+					 GFP_NOWAIT);
+	if (!msg_list_node) {
+		nnp_log_err(GENERAL_LOG, "No memory for message list\n");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < size; i++)
+		msg_list_node->msg[i] = *(msg + i);
+#ifdef _DEBUG
+	for (i = size; i < MSG_SCHED_MAX_MSG_SIZE; i++)
+		msg_list_node->msg[i] = 0xdeadbeefdeadbeefLLU;
+#endif
+
+	msg_list_node->size = size;
+
+	spin_lock_bh(&queue->list_lock_bh);
+	invalid_queue = queue->invalid;
+	if (!invalid_queue) {
+		list_add_tail(&msg_list_node->node, &queue->msgs_list_head);
+		queue->msgs_num++;
+	}
+	spin_unlock_bh(&queue->list_lock_bh);
+
+	/* if queue flaged as invalid - silently ignore the message */
+	if (invalid_queue) {
+		kmem_cache_free(queue->scheduler->slab_cache_ptr,
+				msg_list_node);
+		return 0;
+	}
+
+	spin_lock_bh(&queue->scheduler->queue_lock_bh);
+	queue->scheduler->total_msgs_num++;
+	spin_unlock_bh(&queue->scheduler->queue_lock_bh);
+	wake_up_process(queue->scheduler->scheduler_thread);
+
+	return 0;
+}
+
+void msg_scheduler_queue_make_valid(struct msg_scheduler_queue *queue)
+{
+	spin_lock_bh(&queue->list_lock_bh);
+	queue->invalid = 0;
+	spin_unlock_bh(&queue->list_lock_bh);
+}
+
+/*
+ * [Description]: start dedicate thread to handle message scheduling
+ * - create and start thread.
+ * - allcoate Hw handlers memory
+ */
+struct msg_scheduler *msg_scheduler_create(void)
+{
+	struct msg_scheduler *dev_sched;
+
+	dev_sched = kzalloc(sizeof(*dev_sched), GFP_NOWAIT);
+	if (!dev_sched)
+		goto out;
+
+	dev_sched->slab_cache_ptr = kmem_cache_create("msg_scheduler_slabCache",
+						      sizeof(struct msg_entry),
+						      0, 0, NULL);
+	if (!dev_sched->slab_cache_ptr) {
+		nnp_log_err(START_UP_LOG, "failed to create message scheduler slab cache\n");
+		kfree(dev_sched);
+		dev_sched = NULL;
+		goto out;
+	}
+
+	INIT_LIST_HEAD(&dev_sched->queues_list_head);
+
+	spin_lock_init(&dev_sched->queue_lock_bh);
+
+	mutex_init(&dev_sched->destroy_lock);
+
+	dev_sched->scheduler_thread = kthread_run(msg_scheduler_thread_func,
+						  dev_sched,
+						  "msg_scheduler_thread");
+	if (!dev_sched->scheduler_thread) {
+		nnp_log_err(START_UP_LOG, "failed to create message scheduler thread\n");
+		kmem_cache_destroy(dev_sched->slab_cache_ptr);
+		mutex_destroy(&dev_sched->destroy_lock);
+		kfree(dev_sched);
+		dev_sched = NULL;
+	}
+
+out:
+	return dev_sched;
+}
+
+/*
+ * [Description]: stop scheduler thread, and release all allocated memory
+ *                that still allocated.
+ *
+ * [in] scheduler
+ */
+int msg_scheduler_destroy(struct msg_scheduler *scheduler)
+{
+	struct msg_scheduler_queue *queue_node;
+	int rc;
+
+	msg_scheduler_invalidate_all(scheduler);
+
+	if (scheduler->scheduler_thread) {
+		rc = kthread_stop(scheduler->scheduler_thread);
+		if (rc) {
+			nnp_log_err(GO_DOWN_LOG,
+				    "thread exit code is: %d\n", rc);
+			return -ENOMSG;
+		}
+	}
+
+	spin_lock_bh(&scheduler->queue_lock_bh);
+	while (!list_empty(&scheduler->queues_list_head)) {
+		queue_node =
+			list_first_entry(&scheduler->queues_list_head,
+					 struct msg_scheduler_queue,
+					 queues_list_node);
+
+		/* destroy the queue */
+		list_del(&queue_node->queues_list_node);
+		spin_unlock_bh(&scheduler->queue_lock_bh);
+		kfree(queue_node);
+		spin_lock_bh(&scheduler->queue_lock_bh);
+	}
+	spin_unlock_bh(&scheduler->queue_lock_bh);
+
+	kmem_cache_destroy(scheduler->slab_cache_ptr);
+
+	mutex_destroy(&scheduler->destroy_lock);
+	kfree(scheduler);
+
+	nnp_log_debug(GO_DOWN_LOG, "destroy done\n");
+
+	return 0;
+}
+
+int msg_scheduler_invalidate_all(struct msg_scheduler *scheduler)
+{
+	struct msg_scheduler_queue *queue_node;
+	struct msg_entry *msg_list_node;
+	u32 nq = 0, nmsg = 0;
+
+	mutex_lock(&scheduler->destroy_lock);
+
+	/*
+	 * For each queue:
+	 * 1) invalidate the queue, so that no more messages will be inserted
+	 * 2) delete all existing messages
+	 */
+	spin_lock_bh(&scheduler->queue_lock_bh);
+	list_for_each_entry(queue_node,
+			    &scheduler->queues_list_head,
+			    queues_list_node) {
+		spin_lock_bh(&queue_node->list_lock_bh);
+		queue_node->invalid = 1;
+		while (!list_empty(&queue_node->msgs_list_head)) {
+			msg_list_node =
+				list_first_entry(&queue_node->msgs_list_head,
+						 struct msg_entry, node);
+			list_del(&msg_list_node->node);
+			kmem_cache_free(scheduler->slab_cache_ptr,
+					msg_list_node);
+			nmsg++;
+		}
+		queue_node->msgs_num = 0;
+		spin_unlock_bh(&queue_node->list_lock_bh);
+		wake_up_all(&queue_node->flush_waitq);
+		nq++;
+	}
+	spin_unlock_bh(&scheduler->queue_lock_bh);
+
+	mutex_unlock(&scheduler->destroy_lock);
+
+	nnp_log_debug(GENERAL_LOG,
+		      "Invalidated %d msg queues, total messages lost %d\n",
+		      nq, nmsg);
+
+	return 0;
+}
+
+static int debug_status_show(struct seq_file *m, void *v)
+{
+	struct msg_scheduler *scheduler = m->private;
+	struct msg_scheduler_queue *queue_node;
+	struct msg_entry *msg_list_node;
+	u32 nq = 0, tmsgs = 0;
+
+	spin_lock_bh(&scheduler->queue_lock_bh);
+	list_for_each_entry(queue_node,
+			    &scheduler->queues_list_head,
+			    queues_list_node) {
+		u32 nmsg = 0;
+
+		spin_lock_bh(&queue_node->list_lock_bh);
+		list_for_each_entry(msg_list_node,
+				    &queue_node->msgs_list_head,
+				    node) {
+			nmsg++;
+		}
+		spin_unlock_bh(&queue_node->list_lock_bh);
+#ifdef DEBUG
+		seq_printf(m, "queue 0x%lx: handle_cont=%u msgs_num=%u actual_msgs_num=%u scheds=%u pre=%u post=%u failed=%u\n",
+			   (uintptr_t)queue_node,
+			   queue_node->handle_cont,
+			   queue_node->msgs_num,
+			   nmsg,
+			   queue_node->sched_count,
+			   queue_node->pre_send_count,
+			   queue_node->post_send_count,
+			   queue_node->send_failed_count);
+#else
+		seq_printf(m, "queue 0x%lx: handle_cont=%u msgs_num=%u actual_msgs_num=%u\n",
+			   (uintptr_t)queue_node,
+			   queue_node->handle_cont,
+			   queue_node->msgs_num,
+			   nmsg);
+#endif
+		nq++;
+		tmsgs += nmsg;
+	}
+	seq_printf(m, "%u queues total_msgs=%u actual_total_msgs=%u\n",
+		   nq, scheduler->total_msgs_num, tmsgs);
+	spin_unlock_bh(&scheduler->queue_lock_bh);
+
+	return 0;
+}
+
+static int debug_status_open(struct inode *inode, struct file *filp)
+{
+	return single_open(filp, debug_status_show, inode->i_private);
+}
+
+static const struct file_operations debug_status_fops = {
+	.open		= debug_status_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+void msg_scheduler_init_debugfs(struct msg_scheduler *scheduler,
+				struct dentry *parent,
+				const char    *dirname)
+{
+	struct dentry *dir, *stats;
+
+	if (!parent)
+		return;
+
+	dir = debugfs_create_dir(dirname, parent);
+	if (IS_ERR_OR_NULL(dir))
+		return;
+
+	stats = debugfs_create_file("status",
+				    0444,
+				    dir,
+				    (void *)scheduler,
+				    &debug_status_fops);
+	if (IS_ERR_OR_NULL(stats)) {
+		debugfs_remove(dir);
+		return;
+	}
+}
diff --git a/drivers/misc/intel-nnpi/msg_scheduler.h b/drivers/misc/intel-nnpi/msg_scheduler.h
new file mode 100644
index 0000000..aad8a2b
--- /dev/null
+++ b/drivers/misc/intel-nnpi/msg_scheduler.h
@@ -0,0 +1,147 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+
+/********************************************
+ * Copyright (C) 2019-2020 Intel Corporation
+ ********************************************/
+
+#ifndef _NNP_MSGF_SCHEDULER_H
+#define _NNP_MSGF_SCHEDULER_H
+
+#include <linux/fs.h>
+#include <linux/poll.h>
+#include <linux/workqueue.h>
+#include <linux/mutex.h>
+#include <linux/debugfs.h>
+
+#define MSG_SCHED_MAX_MSG_SIZE 3
+
+/* [Description]: HW handler called by the scheduler to send a message.
+ * [in]: msg: message.
+ * [in]: size[1-2]: size of message.
+ * [in]: hw_data: pointer to device specific hw data attached
+ *                (e.g: struct nnp_device).
+ * [return]: status.
+ */
+typedef int (*hw_handle_msg)(u64 *msg, int size, void *hw_data);
+
+struct msg_scheduler {
+	struct task_struct *scheduler_thread;
+	struct list_head queues_list_head;
+	spinlock_t queue_lock_bh; /* protects queues_list del/inserts */
+	struct mutex destroy_lock; /* serialize q destroy with sched thread */
+	u32 total_msgs_num;
+	struct kmem_cache *slab_cache_ptr;
+};
+
+struct msg_scheduler_queue {
+	struct msg_scheduler *scheduler;
+	struct list_head queues_list_node;
+	struct list_head msgs_list_head;
+	wait_queue_head_t  flush_waitq;
+	u32 invalid;
+	u32 msgs_num;
+	spinlock_t list_lock_bh; /* protects msg_list del/inserts */
+	u32 handle_cont;
+	void *device_hw_data;
+	hw_handle_msg msg_handle;
+#ifdef DEBUG
+	/* Debug statistics counters */
+	u32 sched_count;
+	u32 pre_send_count;
+	u32 post_send_count;
+	u32 send_failed_count;
+#endif
+};
+
+/*********************************************************************
+ *  [Brief]: create messages scheduler
+ *           malloc DB and start dedicated scheduling thread.
+ *
+ *  [return] : dev_scheduler, NULL-failed.
+ ********************************************************************/
+struct msg_scheduler *msg_scheduler_create(void);
+
+/*
+ * @brief - initializes debugfs status entry
+ */
+void msg_scheduler_init_debugfs(struct msg_scheduler *scheduler,
+				struct dentry *parent,
+				const char    *dirname);
+
+/*********************************************************************
+ *  [Brief]: destroy messages scheduler
+ *
+ *  free all remaining messages and queues and stop scheduler running thread.
+ *
+ *  [in] scheduler: scheduler data returned from msg_scheduler_create.
+ *  [return] : 0 - success, otherwise- failed.
+ ********************************************************************/
+int msg_scheduler_destroy(struct msg_scheduler *scheduler);
+
+/**
+ * @brief Remove all messages from all queues and mark all queues
+ *  invalid. invalid queues can only be destroyed, no messages can be added to
+ *  an invalid queue.
+ *  This function is called just before a card reset to prevent any new messages
+ *  to be sent on the h/w queue.
+ */
+int msg_scheduler_invalidate_all(struct msg_scheduler *scheduler);
+
+/*********************************************************************
+ *  [Brief]: create messages queue handled by scheduler.
+ *
+ *  [in] scheduler: scheduler data  returned by "msg_scheduler_create".
+ *  [in] device_hw_data: device specific hw data (e.g: struct nnp_device).
+ *  [in] hw_handle_msg: function pointer to HW message handler.
+ *  [in] conti_msgs: number of messages scheduler may handle contineously before
+ *       moving to next queue.
+ *  [return] : queue - success, NULL-failed.
+ ********************************************************************/
+struct msg_scheduler_queue *msg_scheduler_queue_create(
+					struct msg_scheduler *scheduler,
+					void                 *device_hw_data,
+					hw_handle_msg         msg_handle,
+					u32                   conti_msgs);
+
+/*********************************************************************
+ *  [Brief]: destroy messages queue created by "msg_scheduler_queue_create".
+ *
+ *  [in] scheduler: scheduler data returned by msg_scheduler_create.
+ *  [in] queue: data pointer returned by "msg_scheduler_queue_create".
+ *  [return] : 0 - success, otherwise- failed.
+ ********************************************************************/
+int msg_scheduler_queue_destroy(struct msg_scheduler       *scheduler,
+				struct msg_scheduler_queue *queue);
+
+/*********************************************************************
+ *  [Brief]: wait until a message queue is flushed out and empty
+ *
+ *  [in] queue: data pointer of queue returned by "msg_scheduler_queue_create".
+ *  [return] : 0 - success, otherwise- failed.
+ ********************************************************************/
+int msg_scheduler_queue_flush(struct msg_scheduler_queue *queue);
+
+/*********************************************************************
+ *  [Brief]: add message to queue created in "msg_scheduler_queue_create".
+ *
+ *  [in] queue: data pointer of queue returned by "msg_scheduler_queue_create".
+ *  [in] msg: message value.
+ *  [in] size[1-2]: message size, one/two u64 message/s.
+ *  [return] : 0 - success, otherwise- failed.
+ ********************************************************************/
+int msg_scheduler_queue_add_msg(struct       msg_scheduler_queue *queue,
+				u64         *msg,
+				unsigned int size);
+
+/*********************************************************************
+ *  [Brief]: Marks a queue as valid
+ *
+ *  This function marks a queue as valid again after it made invalid
+ *  by a call to msg_scheduler_invalidate_all.
+ *
+ *  [in] queue: data pointer of queue returned by "msg_scheduler_queue_create".
+ *  [in] msg: message value.
+ ********************************************************************/
+void msg_scheduler_queue_make_valid(struct msg_scheduler_queue *queue);
+
+#endif /* _NNP_MSGF_SCHEDULER_H */
-- 
1.8.3.1

